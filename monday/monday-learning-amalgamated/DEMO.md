# Monday: Learning, Amalgamated - Demo Script

## 3-Minute Demo Flow

This demo showcases all major features of Monday: Learning, Amalgamated in a carefully orchestrated sequence.

### Setup (30 seconds)
1. **Environment Check**
   - Quest headset on and connected
   - Application running on `https://YOUR_IP_ADDRESS`
   - Microphone permissions granted
   - SSL certificate accepted

2. **Initial State**
   - Dark VR space with Perplexity branding
   - Turquoise asterisk pulsing in center
   - Monday's welcoming presence

### Demo Sequence

#### 1. Natural Voice Interaction (30 seconds)
**Script**: "Monday, hello"

**Expected Response**: 
- Asterisk animates to show Monday is listening
- Monday's warm voice responds: "Hello! I'm Monday, your AI learning companion. I'm here to help you explore knowledge in three dimensions. What would you like to learn about today?"
- Voice interface appears at bottom showing recognition status

**Demonstrates**: 
- Voice-first interaction
- Monday's personality
- Perplexity brand integration

#### 2. Basic Query with 3D Visualization (45 seconds)
**Script**: "Monday, explain binary trees"

**Expected Response**:
- Monday processes the query using Perplexity Sonar Basic API
- 3D binary tree visualization materializes in space
- Information panel appears with explanation
- Nodes animate to show insertion/deletion operations
- Citations appear as small turquoise nodes

**Demonstrates**:
- Basic Perplexity integration
- 3D concept visualization
- Spatial information display
- Citation handling

#### 3. Reasoning Mode with Visible Thought Process (45 seconds)
**Script**: "Monday, think about how recursion works in programming"

**Expected Response**:
- Monday switches to reasoning mode
- Animated spiral of connected reasoning steps appears
- Each step shows confidence with varying glow intensity
- Logical connections between steps are visualized
- Comprehensive breakdown of recursion concept

**Demonstrates**:
- Perplexity Sonar Reasoning Pro integration
- Reasoning chain visualization
- Confidence scoring display
- Step-by-step learning approach

#### 4. Deep Research with Knowledge Web (45 seconds)
**Script**: "Monday, deep dive on machine learning algorithms"

**Expected Response**:
- Space expands dramatically for research mode
- Multiple sources appear as nodes in constellation
- Research synthesis happens visually
- Connections form between related concepts
- Expanding knowledge web shows source relationships

**Demonstrates**:
- Perplexity Sonar Deep Research integration
- Multi-source analysis
- Knowledge graph visualization
- Research synthesis capabilities

#### 5. Spatial Manipulation and Focus Features (15 seconds)
**Script**: "Monday, bring this closer" (referring to ML content)

**Expected Response**:
- Selected content smoothly moves toward user
- Becomes primary focus with full opacity
- Other panels fade to 20% opacity
- Focus mode automatically engages

**Script**: "Monday, focus mode"

**Expected Response**:
- All non-active panels dim to 15%
- Active content centered and highlighted
- Distraction-free learning environment

**Demonstrates**:
- Voice-controlled spatial interaction
- Focus mode for concentration
- Automatic content orchestration

### Key Features Highlighted

#### Technical Excellence
- **WebXR Performance**: Smooth 72 FPS on Quest hardware
- **Voice Recognition**: Continuous listening with "Monday" activation
- **Real-time Communication**: WebSocket-based instant responses
- **Spatial Computing**: Automatic 3D layout management

#### Educational Innovation
- **Three Learning Modes**: Basic, Reasoning, Deep Research
- **Visual Learning**: 3D concepts become spatially memorable
- **Progressive Complexity**: Monday adapts to user understanding
- **Context Retention**: Reference previous discussions

#### User Experience
- **Voice-First**: No manual UI manipulation required
- **Perplexity Branding**: Consistent visual identity
- **Ambient Intelligence**: Monday manages the entire knowledge space
- **Encouraging Personality**: Professional yet approachable

### Demo Talking Points

#### For Technical Audience
- "Built on WebXR for native VR browser support"
- "Integrates all three Perplexity Sonar API tiers"
- "Real-time WebSocket communication"
- "Quest-optimized performance with automatic quality scaling"

#### For Educational Audience
- "Transforms abstract concepts into spatial experiences"
- "Monday remembers your learning journey"
- "Voice-first interaction removes barriers"
- "3D visualizations make complex topics memorable"

#### For Business Audience
- "Leverages cutting-edge Perplexity AI technology"
- "Scalable architecture with Docker deployment"
- "Quest 2/3 compatibility reaches massive VR market"
- "Minimal hardware requirements - just a headset"

### Demo Recovery Scenarios

#### If Voice Recognition Fails
- Fall back to typing in browser console
- Demonstrate with pre-recorded commands
- Show voice interface working on desktop

#### If VR Performance Issues
- Switch to desktop browser mode
- Reduce quality settings automatically
- Show performance monitoring in dev mode

#### If API Issues
- Use cached/mock responses
- Demonstrate UI and spatial features
- Show offline visualization capabilities

### Post-Demo Discussion Points

1. **Scalability**: How Monday could expand to other subject areas
2. **Personalization**: Learning path optimization based on user progress
3. **Collaboration**: Multi-user VR learning sessions
4. **Integration**: Embedding in educational platforms
5. **Analytics**: Learning effectiveness measurement

### Technical Requirements for Demo

- **Hardware**: Quest 2/3, development machine
- **Network**: Stable WiFi for both devices
- **APIs**: Valid Perplexity and ElevenLabs keys
- **Environment**: Quiet space for voice commands
- **Backup**: Pre-recorded demo video if live demo fails

### Demo Checklist

**Before Demo**:
- [ ] Quest charged and connected
- [ ] Application running and tested
- [ ] Voice commands rehearsed
- [ ] API keys valid and working
- [ ] Network connection stable
- [ ] Backup plan ready

**During Demo**:
- [ ] Speak clearly toward Quest microphone
- [ ] Allow pauses for Monday to respond
- [ ] Gesture toward 3D elements when discussing
- [ ] Maintain enthusiasm and energy
- [ ] Watch for audience engagement

**After Demo**:
- [ ] Answer technical questions
- [ ] Show code architecture if requested
- [ ] Discuss implementation timeline
- [ ] Provide development resources
- [ ] Schedule follow-up meetings

This demo script ensures a comprehensive showcase of Monday's capabilities while maintaining engagement and demonstrating real value for VR-based learning. 